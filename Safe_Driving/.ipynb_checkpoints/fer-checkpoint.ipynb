{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DApS1M-ry10g"
   },
   "source": [
    "## Classifying Crops by Inception V3, VGG16 and own model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fAvMeqAYy13o"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ieFMcxNCy13y"
   },
   "outputs": [],
   "source": [
    "# import  libraries \n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qWYdS3Wpa1oN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtiJ1V9VMqmm"
   },
   "source": [
    "# DATA separating and resize for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pSvDLGrzy139"
   },
   "outputs": [],
   "source": [
    "# re-size \n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'train'\n",
    "valid_path = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RRSv7N3sy15U"
   },
   "outputs": [],
   "source": [
    "#Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArKo_cO8y15W",
    "outputId": "4b81742d-cfdd-48b7-c28e-c22259e71365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5028 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# providing the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq1wA80yy15Y",
    "outputId": "5adf0e8d-9a64-4df5-f0cf-7ff1c8ba9a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QwG0A5YpZxb0"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import *\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      TruePositives(name='tp'),\n",
    "      FalsePositives(name='fp'),\n",
    "      TrueNegatives(name='tn'),\n",
    "      FalseNegatives(name='fn'), \n",
    "      BinaryAccuracy(name='accuracy'),\n",
    "      Precision(name='precision'),\n",
    "      Recall(name='recall'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2K551kCL-ep"
   },
   "source": [
    "# Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLQ666bTMCpO",
    "outputId": "4e82d89c-cd7e-4ac7-81f8-a01954ee5937"
   },
   "outputs": [],
   "source": [
    "# Import the InceptionV3 library \n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0wee8A61MIP7"
   },
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oVFQl0NLMIU_"
   },
   "outputs": [],
   "source": [
    "# our layers \n",
    "x = Flatten()(inception.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kJLQ8-LbMIZb"
   },
   "outputs": [],
   "source": [
    "prediction = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model1 = Model(inputs=inception.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8feVl0-iMId3"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model1.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "ld2I-thVy15a",
    "outputId": "f062180e-f2d5-453e-d88b-b8ae65ca8571",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-f327ae07ac14>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model1.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 228s 708ms/step - loss: 3.4700 - tp: 3243.0000 - fp: 1735.0000 - tn: 23405.0000 - fn: 1785.0000 - accuracy: 0.8833 - precision: 0.6515 - recall: 0.6450 - val_loss: 3.7050 - val_tp: 108.0000 - val_fp: 47.0000 - val_tn: 733.0000 - val_fn: 48.0000 - val_accuracy: 0.8985 - val_precision: 0.6968 - val_recall: 0.6923\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 225s 713ms/step - loss: 3.2860 - tp: 3559.0000 - fp: 1458.0000 - tn: 23682.0000 - fn: 1469.0000 - accuracy: 0.9030 - precision: 0.7094 - recall: 0.7078 - val_loss: 3.5319 - val_tp: 121.0000 - val_fp: 35.0000 - val_tn: 745.0000 - val_fn: 35.0000 - val_accuracy: 0.9252 - val_precision: 0.7756 - val_recall: 0.7756\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 224s 711ms/step - loss: 3.2697 - tp: 3728.0000 - fp: 1285.0000 - tn: 23855.0000 - fn: 1300.0000 - accuracy: 0.9143 - precision: 0.7437 - recall: 0.7414 - val_loss: 6.3977 - val_tp: 106.0000 - val_fp: 50.0000 - val_tn: 730.0000 - val_fn: 50.0000 - val_accuracy: 0.8932 - val_precision: 0.6795 - val_recall: 0.6795\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 223s 707ms/step - loss: 2.8787 - tp: 3840.0000 - fp: 1174.0000 - tn: 23966.0000 - fn: 1188.0000 - accuracy: 0.9217 - precision: 0.7659 - recall: 0.7637 - val_loss: 2.8692 - val_tp: 123.0000 - val_fp: 33.0000 - val_tn: 747.0000 - val_fn: 33.0000 - val_accuracy: 0.9295 - val_precision: 0.7885 - val_recall: 0.7885\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 219s 694ms/step - loss: 2.3439 - tp: 3944.0000 - fp: 1076.0000 - tn: 24064.0000 - fn: 1084.0000 - accuracy: 0.9284 - precision: 0.7857 - recall: 0.7844 - val_loss: 2.5324 - val_tp: 127.0000 - val_fp: 29.0000 - val_tn: 751.0000 - val_fn: 29.0000 - val_accuracy: 0.9380 - val_precision: 0.8141 - val_recall: 0.8141\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.1011 - tp: 3992.0000 - fp: 1027.0000 - tn: 24113.0000 - fn: 1036.0000 - accuracy: 0.9316 - precision: 0.7954 - recall: 0.7940 - val_loss: 3.2432 - val_tp: 125.0000 - val_fp: 29.0000 - val_tn: 751.0000 - val_fn: 31.0000 - val_accuracy: 0.9359 - val_precision: 0.8117 - val_recall: 0.8013\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.1822 - tp: 4049.0000 - fp: 971.0000 - tn: 24169.0000 - fn: 979.0000 - accuracy: 0.9354 - precision: 0.8066 - recall: 0.8053 - val_loss: 3.2372 - val_tp: 120.0000 - val_fp: 36.0000 - val_tn: 744.0000 - val_fn: 36.0000 - val_accuracy: 0.9231 - val_precision: 0.7692 - val_recall: 0.7692\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.3246 - tp: 4056.0000 - fp: 965.0000 - tn: 24175.0000 - fn: 972.0000 - accuracy: 0.9358 - precision: 0.8078 - recall: 0.8067 - val_loss: 3.8220 - val_tp: 115.0000 - val_fp: 41.0000 - val_tn: 739.0000 - val_fn: 41.0000 - val_accuracy: 0.9124 - val_precision: 0.7372 - val_recall: 0.7372\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.1379 - tp: 4068.0000 - fp: 956.0000 - tn: 24184.0000 - fn: 960.0000 - accuracy: 0.9365 - precision: 0.8097 - recall: 0.8091 - val_loss: 2.9763 - val_tp: 128.0000 - val_fp: 28.0000 - val_tn: 752.0000 - val_fn: 28.0000 - val_accuracy: 0.9402 - val_precision: 0.8205 - val_recall: 0.8205\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 204s 646ms/step - loss: 2.1784 - tp: 4097.0000 - fp: 924.0000 - tn: 24216.0000 - fn: 931.0000 - accuracy: 0.9385 - precision: 0.8160 - recall: 0.8148 - val_loss: 3.8524 - val_tp: 125.0000 - val_fp: 31.0000 - val_tn: 749.0000 - val_fn: 31.0000 - val_accuracy: 0.9338 - val_precision: 0.8013 - val_recall: 0.8013\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 204s 649ms/step - loss: 1.9504 - tp: 4179.0000 - fp: 844.0000 - tn: 24296.0000 - fn: 849.0000 - accuracy: 0.9439 - precision: 0.8320 - recall: 0.8311 - val_loss: 1.9237 - val_tp: 134.0000 - val_fp: 22.0000 - val_tn: 758.0000 - val_fn: 22.0000 - val_accuracy: 0.9530 - val_precision: 0.8590 - val_recall: 0.8590\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.0380 - tp: 4183.0000 - fp: 842.0000 - tn: 24298.0000 - fn: 845.0000 - accuracy: 0.9441 - precision: 0.8324 - recall: 0.8319 - val_loss: 3.1178 - val_tp: 127.0000 - val_fp: 29.0000 - val_tn: 751.0000 - val_fn: 29.0000 - val_accuracy: 0.9380 - val_precision: 0.8141 - val_recall: 0.8141\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 204s 647ms/step - loss: 1.9838 - tp: 4199.0000 - fp: 825.0000 - tn: 24315.0000 - fn: 829.0000 - accuracy: 0.9452 - precision: 0.8358 - recall: 0.8351 - val_loss: 3.2379 - val_tp: 122.0000 - val_fp: 34.0000 - val_tn: 746.0000 - val_fn: 34.0000 - val_accuracy: 0.9274 - val_precision: 0.7821 - val_recall: 0.7821\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 2.1698 - tp: 4168.0000 - fp: 858.0000 - tn: 24282.0000 - fn: 860.0000 - accuracy: 0.9431 - precision: 0.8293 - recall: 0.8290 - val_loss: 4.3532 - val_tp: 124.0000 - val_fp: 32.0000 - val_tn: 748.0000 - val_fn: 32.0000 - val_accuracy: 0.9316 - val_precision: 0.7949 - val_recall: 0.7949\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 208s 659ms/step - loss: 1.7869 - tp: 4259.0000 - fp: 764.0000 - tn: 24376.0000 - fn: 769.0000 - accuracy: 0.9492 - precision: 0.8479 - recall: 0.8471 - val_loss: 4.7817 - val_tp: 124.0000 - val_fp: 32.0000 - val_tn: 748.0000 - val_fn: 32.0000 - val_accuracy: 0.9316 - val_precision: 0.7949 - val_recall: 0.7949\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 204s 649ms/step - loss: 1.8856 - tp: 4235.0000 - fp: 792.0000 - tn: 24348.0000 - fn: 793.0000 - accuracy: 0.9475 - precision: 0.8425 - recall: 0.8423 - val_loss: 3.4292 - val_tp: 127.0000 - val_fp: 29.0000 - val_tn: 751.0000 - val_fn: 29.0000 - val_accuracy: 0.9380 - val_precision: 0.8141 - val_recall: 0.8141\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 205s 650ms/step - loss: 1.8084 - tp: 4263.0000 - fp: 760.0000 - tn: 24380.0000 - fn: 765.0000 - accuracy: 0.9494 - precision: 0.8487 - recall: 0.8479 - val_loss: 4.5775 - val_tp: 120.0000 - val_fp: 36.0000 - val_tn: 744.0000 - val_fn: 36.0000 - val_accuracy: 0.9231 - val_precision: 0.7692 - val_recall: 0.7692\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 1.7080 - tp: 4342.0000 - fp: 684.0000 - tn: 24456.0000 - fn: 686.0000 - accuracy: 0.9546 - precision: 0.8639 - recall: 0.8636 - val_loss: 2.6498 - val_tp: 129.0000 - val_fp: 27.0000 - val_tn: 753.0000 - val_fn: 27.0000 - val_accuracy: 0.9423 - val_precision: 0.8269 - val_recall: 0.8269\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 204s 647ms/step - loss: 1.8040 - tp: 4294.0000 - fp: 731.0000 - tn: 24409.0000 - fn: 734.0000 - accuracy: 0.9514 - precision: 0.8545 - recall: 0.8540 - val_loss: 3.9919 - val_tp: 123.0000 - val_fp: 33.0000 - val_tn: 747.0000 - val_fn: 33.0000 - val_accuracy: 0.9295 - val_precision: 0.7885 - val_recall: 0.7885\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 204s 648ms/step - loss: 1.4612 - tp: 4387.0000 - fp: 638.0000 - tn: 24502.0000 - fn: 641.0000 - accuracy: 0.9576 - precision: 0.8730 - recall: 0.8725 - val_loss: 4.6939 - val_tp: 128.0000 - val_fp: 28.0000 - val_tn: 752.0000 - val_fn: 28.0000 - val_accuracy: 0.9402 - val_precision: 0.8205 - val_recall: 0.8205\n"
     ]
    }
   ],
   "source": [
    "# # fit the model\n",
    "\n",
    "r = model1.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.save('inception_v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFVFQYRW0d-b"
   },
   "source": [
    "# USING VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2-OEOxIu0i8d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MBNDnV5g0rWv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Flatten,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lA7XLDRa1R3v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'block5_pool')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_size=[224,224]\n",
    "vgg=VGG16(input_shape=Image_size+[3],weights='imagenet',include_top=False)\n",
    "vgg.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dYBvlAnU1ZOw"
   },
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "TYlfp4-H1pij"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 150534    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,865,222\n",
      "Trainable params: 150,534\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=Flatten()(vgg.output)\n",
    "prediction=Dense(6,activation='softmax')(x)\n",
    "model2=Model(inputs=vgg.input,outputs=prediction)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9D2EklIG1wEd"
   },
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6MSs7B-j10YA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-258b1d4b3a8d>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model2.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 836s 3s/step - loss: 0.8519 - accuracy: 0.6611 - val_loss: 0.6479 - val_accuracy: 0.7372\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 834s 3s/step - loss: 0.7029 - accuracy: 0.7311 - val_loss: 0.5311 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 835s 3s/step - loss: 0.6155 - accuracy: 0.7613 - val_loss: 0.5486 - val_accuracy: 0.7692\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 832s 3s/step - loss: 0.5708 - accuracy: 0.7812 - val_loss: 0.5961 - val_accuracy: 0.7756\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 832s 3s/step - loss: 0.5206 - accuracy: 0.8003 - val_loss: 0.6490 - val_accuracy: 0.7756\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 835s 3s/step - loss: 0.5312 - accuracy: 0.7977 - val_loss: 0.4885 - val_accuracy: 0.8205\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 837s 3s/step - loss: 0.4866 - accuracy: 0.8125 - val_loss: 0.4402 - val_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 842s 3s/step - loss: 0.4268 - accuracy: 0.8379 - val_loss: 0.5959 - val_accuracy: 0.7821\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 837s 3s/step - loss: 0.4606 - accuracy: 0.8288 - val_loss: 0.5740 - val_accuracy: 0.7949\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 836s 3s/step - loss: 0.4262 - accuracy: 0.8298 - val_loss: 0.6915 - val_accuracy: 0.8077\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 835s 3s/step - loss: 0.4361 - accuracy: 0.8375 - val_loss: 0.6931 - val_accuracy: 0.8013\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 840s 3s/step - loss: 0.4010 - accuracy: 0.8449 - val_loss: 0.7165 - val_accuracy: 0.7821\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 840s 3s/step - loss: 0.4222 - accuracy: 0.8369 - val_loss: 0.4636 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 839s 3s/step - loss: 0.3720 - accuracy: 0.8600 - val_loss: 0.5249 - val_accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 837s 3s/step - loss: 0.3703 - accuracy: 0.8546 - val_loss: 0.5989 - val_accuracy: 0.8269\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 841s 3s/step - loss: 0.3891 - accuracy: 0.8546 - val_loss: 0.5092 - val_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 837s 3s/step - loss: 0.3617 - accuracy: 0.8624 - val_loss: 0.5947 - val_accuracy: 0.8269\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 836s 3s/step - loss: 0.3787 - accuracy: 0.8588 - val_loss: 0.9224 - val_accuracy: 0.7372\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 837s 3s/step - loss: 0.3438 - accuracy: 0.8695 - val_loss: 0.6914 - val_accuracy: 0.7628\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 838s 3s/step - loss: 0.3280 - accuracy: 0.8733 - val_loss: 0.6922 - val_accuracy: 0.7885\n"
     ]
    }
   ],
   "source": [
    "# # fit the model\n",
    "\n",
    "r = model2.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save('vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTY29z_ubpUV"
   },
   "source": [
    "# Using own CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kgmwfdQvbnjV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_94 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 112, 112, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 56, 56, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 50176)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               6422656   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,452,070\n",
      "Trainable params: 6,452,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# I have used 3 Convolutional layers followed by max-pooling layers, a drop layer and 2 dense layer\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model3.add(MaxPool2D())\n",
    "\n",
    "\n",
    "model3.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model3.add(MaxPool2D())\n",
    "\n",
    "\n",
    "model3.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model3.add(MaxPool2D())\n",
    "model3.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128,activation=\"relu\"))\n",
    "model3.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Xjv-SSBwbwFE"
   },
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-7a1f4646b6bc>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model3.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "315/315 [==============================] - 195s 617ms/step - loss: 1.2920 - accuracy: 0.4914 - val_loss: 0.7418 - val_accuracy: 0.6474\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.9562 - accuracy: 0.6104 - val_loss: 0.6277 - val_accuracy: 0.6923\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 192s 609ms/step - loss: 0.8765 - accuracy: 0.6450 - val_loss: 0.6083 - val_accuracy: 0.7372\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.8288 - accuracy: 0.6683 - val_loss: 0.6101 - val_accuracy: 0.7244\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.7831 - accuracy: 0.6780 - val_loss: 0.5563 - val_accuracy: 0.7564\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.7394 - accuracy: 0.7078 - val_loss: 0.5810 - val_accuracy: 0.7308\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.7181 - accuracy: 0.7011 - val_loss: 0.5635 - val_accuracy: 0.7436\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.6985 - accuracy: 0.7152 - val_loss: 0.5513 - val_accuracy: 0.7564\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.6637 - accuracy: 0.7291 - val_loss: 0.5318 - val_accuracy: 0.8141\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.6502 - accuracy: 0.7412 - val_loss: 0.6136 - val_accuracy: 0.7308\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.6277 - accuracy: 0.7484 - val_loss: 0.6218 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 191s 607ms/step - loss: 0.6131 - accuracy: 0.7462 - val_loss: 0.5109 - val_accuracy: 0.8013\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.5945 - accuracy: 0.7582 - val_loss: 0.5137 - val_accuracy: 0.7885\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 191s 605ms/step - loss: 0.5892 - accuracy: 0.7613 - val_loss: 0.5581 - val_accuracy: 0.8013\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.5736 - accuracy: 0.7649 - val_loss: 0.5032 - val_accuracy: 0.8013\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.5701 - accuracy: 0.7697 - val_loss: 0.5164 - val_accuracy: 0.8205\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.5501 - accuracy: 0.7792 - val_loss: 0.5844 - val_accuracy: 0.7692\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 191s 605ms/step - loss: 0.5485 - accuracy: 0.7802 - val_loss: 0.6118 - val_accuracy: 0.7628\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 191s 606ms/step - loss: 0.5309 - accuracy: 0.7832 - val_loss: 0.5079 - val_accuracy: 0.8205\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 193s 611ms/step - loss: 0.5250 - accuracy: 0.7942 - val_loss: 0.5163 - val_accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "# # fit the model\n",
    "\n",
    "r = model3.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-XQxn8HanD-"
   },
   "source": [
    "# Mobile NET V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "IVetAVWZaxX1"
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(tf.keras.applications.MobileNetV2(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(6, activation='sigmoid'))\n",
    "model4.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wpxZtH6pbSks"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model4.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "z7xclj3MbgAD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-6ef08da00759>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model4.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "315/315 [==============================] - 130s 403ms/step - loss: 0.8627 - tp: 3687.0000 - fp: 4823.0000 - tn: 21097.0000 - fn: 1497.0000 - accuracy: 0.7968 - precision: 0.4333 - recall: 0.7112 - val_loss: 0.7220 - val_tp: 105.0000 - val_fp: 89.0000 - val_tn: 691.0000 - val_fn: 51.0000 - val_accuracy: 0.8504 - val_precision: 0.5412 - val_recall: 0.6731\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.6726 - tp: 3568.0000 - fp: 3047.0000 - tn: 22093.0000 - fn: 1460.0000 - accuracy: 0.8506 - precision: 0.5394 - recall: 0.7096 - val_loss: 0.6660 - val_tp: 118.0000 - val_fp: 96.0000 - val_tn: 684.0000 - val_fn: 38.0000 - val_accuracy: 0.8568 - val_precision: 0.5514 - val_recall: 0.7564\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 127s 401ms/step - loss: 0.6265 - tp: 3566.0000 - fp: 2514.0000 - tn: 22626.0000 - fn: 1462.0000 - accuracy: 0.8682 - precision: 0.5865 - recall: 0.7092 - val_loss: 0.6934 - val_tp: 121.0000 - val_fp: 82.0000 - val_tn: 698.0000 - val_fn: 35.0000 - val_accuracy: 0.8750 - val_precision: 0.5961 - val_recall: 0.7756\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 127s 401ms/step - loss: 0.6126 - tp: 3698.0000 - fp: 2575.0000 - tn: 22565.0000 - fn: 1330.0000 - accuracy: 0.8706 - precision: 0.5895 - recall: 0.7355 - val_loss: 0.6599 - val_tp: 113.0000 - val_fp: 76.0000 - val_tn: 704.0000 - val_fn: 43.0000 - val_accuracy: 0.8729 - val_precision: 0.5979 - val_recall: 0.7244\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.5793 - tp: 3911.0000 - fp: 2624.0000 - tn: 22516.0000 - fn: 1117.0000 - accuracy: 0.8760 - precision: 0.5985 - recall: 0.7778 - val_loss: 0.6697 - val_tp: 115.0000 - val_fp: 67.0000 - val_tn: 713.0000 - val_fn: 41.0000 - val_accuracy: 0.8846 - val_precision: 0.6319 - val_recall: 0.7372\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 126s 401ms/step - loss: 0.5642 - tp: 3964.0000 - fp: 2480.0000 - tn: 22660.0000 - fn: 1064.0000 - accuracy: 0.8825 - precision: 0.6151 - recall: 0.7884 - val_loss: 0.6457 - val_tp: 118.0000 - val_fp: 76.0000 - val_tn: 704.0000 - val_fn: 38.0000 - val_accuracy: 0.8782 - val_precision: 0.6082 - val_recall: 0.7564\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 143s 452ms/step - loss: 0.5480 - tp: 3875.0000 - fp: 2391.0000 - tn: 22749.0000 - fn: 1153.0000 - accuracy: 0.8825 - precision: 0.6184 - recall: 0.7707 - val_loss: 0.6945 - val_tp: 128.0000 - val_fp: 94.0000 - val_tn: 686.0000 - val_fn: 28.0000 - val_accuracy: 0.8697 - val_precision: 0.5766 - val_recall: 0.8205\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 141s 449ms/step - loss: 0.5447 - tp: 4123.0000 - fp: 2831.0000 - tn: 22309.0000 - fn: 905.0000 - accuracy: 0.8762 - precision: 0.5929 - recall: 0.8200 - val_loss: 0.6667 - val_tp: 115.0000 - val_fp: 64.0000 - val_tn: 716.0000 - val_fn: 41.0000 - val_accuracy: 0.8878 - val_precision: 0.6425 - val_recall: 0.7372\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 142s 450ms/step - loss: 0.5372 - tp: 4180.0000 - fp: 2926.0000 - tn: 22214.0000 - fn: 848.0000 - accuracy: 0.8749 - precision: 0.5882 - recall: 0.8313 - val_loss: 0.5880 - val_tp: 124.0000 - val_fp: 74.0000 - val_tn: 706.0000 - val_fn: 32.0000 - val_accuracy: 0.8868 - val_precision: 0.6263 - val_recall: 0.7949\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 142s 451ms/step - loss: 0.5293 - tp: 4203.0000 - fp: 2944.0000 - tn: 22196.0000 - fn: 825.0000 - accuracy: 0.8751 - precision: 0.5881 - recall: 0.8359 - val_loss: 0.7559 - val_tp: 126.0000 - val_fp: 78.0000 - val_tn: 702.0000 - val_fn: 30.0000 - val_accuracy: 0.8846 - val_precision: 0.6176 - val_recall: 0.8077\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 142s 450ms/step - loss: 0.5209 - tp: 4177.0000 - fp: 2690.0000 - tn: 22450.0000 - fn: 851.0000 - accuracy: 0.8826 - precision: 0.6083 - recall: 0.8307 - val_loss: 0.6520 - val_tp: 122.0000 - val_fp: 74.0000 - val_tn: 706.0000 - val_fn: 34.0000 - val_accuracy: 0.8846 - val_precision: 0.6224 - val_recall: 0.7821\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 132s 418ms/step - loss: 0.5179 - tp: 4266.0000 - fp: 2824.0000 - tn: 22316.0000 - fn: 762.0000 - accuracy: 0.8811 - precision: 0.6017 - recall: 0.8484 - val_loss: 0.6901 - val_tp: 124.0000 - val_fp: 95.0000 - val_tn: 685.0000 - val_fn: 32.0000 - val_accuracy: 0.8643 - val_precision: 0.5662 - val_recall: 0.7949\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 127s 401ms/step - loss: 0.4998 - tp: 4358.0000 - fp: 2966.0000 - tn: 22174.0000 - fn: 670.0000 - accuracy: 0.8795 - precision: 0.5950 - recall: 0.8667 - val_loss: 0.5395 - val_tp: 125.0000 - val_fp: 63.0000 - val_tn: 717.0000 - val_fn: 31.0000 - val_accuracy: 0.8996 - val_precision: 0.6649 - val_recall: 0.8013\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4944 - tp: 4284.0000 - fp: 2659.0000 - tn: 22481.0000 - fn: 744.0000 - accuracy: 0.8872 - precision: 0.6170 - recall: 0.8520 - val_loss: 0.6429 - val_tp: 122.0000 - val_fp: 80.0000 - val_tn: 700.0000 - val_fn: 34.0000 - val_accuracy: 0.8782 - val_precision: 0.6040 - val_recall: 0.7821\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4920 - tp: 4347.0000 - fp: 2763.0000 - tn: 22377.0000 - fn: 681.0000 - accuracy: 0.8858 - precision: 0.6114 - recall: 0.8646 - val_loss: 0.5371 - val_tp: 127.0000 - val_fp: 77.0000 - val_tn: 703.0000 - val_fn: 29.0000 - val_accuracy: 0.8868 - val_precision: 0.6225 - val_recall: 0.8141\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4762 - tp: 4367.0000 - fp: 2933.0000 - tn: 22207.0000 - fn: 661.0000 - accuracy: 0.8809 - precision: 0.5982 - recall: 0.8685 - val_loss: 0.5721 - val_tp: 131.0000 - val_fp: 88.0000 - val_tn: 692.0000 - val_fn: 25.0000 - val_accuracy: 0.8793 - val_precision: 0.5982 - val_recall: 0.8397\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4750 - tp: 4391.0000 - fp: 2916.0000 - tn: 22224.0000 - fn: 637.0000 - accuracy: 0.8822 - precision: 0.6009 - recall: 0.8733 - val_loss: 0.5667 - val_tp: 129.0000 - val_fp: 82.0000 - val_tn: 698.0000 - val_fn: 27.0000 - val_accuracy: 0.8835 - val_precision: 0.6114 - val_recall: 0.8269\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4854 - tp: 4254.0000 - fp: 2617.0000 - tn: 22523.0000 - fn: 774.0000 - accuracy: 0.8876 - precision: 0.6191 - recall: 0.8461 - val_loss: 0.7461 - val_tp: 121.0000 - val_fp: 79.0000 - val_tn: 701.0000 - val_fn: 35.0000 - val_accuracy: 0.8782 - val_precision: 0.6050 - val_recall: 0.7756\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 127s 402ms/step - loss: 0.4697 - tp: 4390.0000 - fp: 2792.0000 - tn: 22348.0000 - fn: 638.0000 - accuracy: 0.8863 - precision: 0.6113 - recall: 0.8731 - val_loss: 0.6666 - val_tp: 125.0000 - val_fp: 85.0000 - val_tn: 695.0000 - val_fn: 31.0000 - val_accuracy: 0.8761 - val_precision: 0.5952 - val_recall: 0.8013\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 127s 403ms/step - loss: 0.4748 - tp: 4483.0000 - fp: 3255.0000 - tn: 21885.0000 - fn: 545.0000 - accuracy: 0.8740 - precision: 0.5793 - recall: 0.8916 - val_loss: 0.6537 - val_tp: 140.0000 - val_fp: 105.0000 - val_tn: 675.0000 - val_fn: 16.0000 - val_accuracy: 0.8707 - val_precision: 0.5714 - val_recall: 0.8974\n"
     ]
    }
   ],
   "source": [
    "# # fit the model\n",
    "\n",
    "r = model4.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4.save('mobile_net_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLbbpcMNbpEq"
   },
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JT_LUxuxbuDf"
   },
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet201, DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1TXlMoFLbwy4"
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(DenseNet121(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\n",
    "model5.add(Dense(512, activation='relu'))\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(Dense(64, activation='relu'))\n",
    "model5.add(Dense(6, activation='sigmoid'))\n",
    "model5.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rRLjS7JXbytj"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model5.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lu7nkyDRb4sp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-aa5eccc02aa8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model5.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "315/315 [==============================] - 442s 1s/step - loss: 0.7930 - tp: 4819.0000 - fp: 8224.0000 - tn: 16916.0000 - fn: 209.0000 - accuracy: 0.7205 - precision: 0.3695 - recall: 0.9584 - val_loss: 0.7201 - val_tp: 151.0000 - val_fp: 208.0000 - val_tn: 572.0000 - val_fn: 5.0000 - val_accuracy: 0.7724 - val_precision: 0.4206 - val_recall: 0.9679\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 422s 1s/step - loss: 0.6600 - tp: 4957.0000 - fp: 7938.0000 - tn: 17202.0000 - fn: 71.0000 - accuracy: 0.7345 - precision: 0.3844 - recall: 0.9859 - val_loss: 0.6447 - val_tp: 156.0000 - val_fp: 224.0000 - val_tn: 556.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7607 - val_precision: 0.4105 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 422s 1s/step - loss: 0.6142 - tp: 4943.0000 - fp: 7499.0000 - tn: 17641.0000 - fn: 85.0000 - accuracy: 0.7486 - precision: 0.3973 - recall: 0.9831 - val_loss: 0.7096 - val_tp: 152.0000 - val_fp: 218.0000 - val_tn: 562.0000 - val_fn: 4.0000 - val_accuracy: 0.7628 - val_precision: 0.4108 - val_recall: 0.9744\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 438s 1s/step - loss: 0.6018 - tp: 4951.0000 - fp: 7611.0000 - tn: 17529.0000 - fn: 77.0000 - accuracy: 0.7452 - precision: 0.3941 - recall: 0.9847 - val_loss: 0.6480 - val_tp: 153.0000 - val_fp: 226.0000 - val_tn: 554.0000 - val_fn: 3.0000 - val_accuracy: 0.7553 - val_precision: 0.4037 - val_recall: 0.9808\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 428s 1s/step - loss: 0.5753 - tp: 4965.0000 - fp: 7607.0000 - tn: 17533.0000 - fn: 63.0000 - accuracy: 0.7458 - precision: 0.3949 - recall: 0.9875 - val_loss: 0.5985 - val_tp: 156.0000 - val_fp: 209.0000 - val_tn: 571.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7767 - val_precision: 0.4274 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.5698 - tp: 4964.0000 - fp: 7452.0000 - tn: 17688.0000 - fn: 64.0000 - accuracy: 0.7509 - precision: 0.3998 - recall: 0.9873 - val_loss: 0.5613 - val_tp: 154.0000 - val_fp: 201.0000 - val_tn: 579.0000 - val_fn: 2.0000 - val_accuracy: 0.7831 - val_precision: 0.4338 - val_recall: 0.9872\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.5539 - tp: 4960.0000 - fp: 7428.0000 - tn: 17712.0000 - fn: 68.0000 - accuracy: 0.7515 - precision: 0.4004 - recall: 0.9865 - val_loss: 0.5943 - val_tp: 155.0000 - val_fp: 205.0000 - val_tn: 575.0000 - val_fn: 1.0000 - val_accuracy: 0.7799 - val_precision: 0.4306 - val_recall: 0.9936\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 402s 1s/step - loss: 0.5302 - tp: 4973.0000 - fp: 7288.0000 - tn: 17852.0000 - fn: 55.0000 - accuracy: 0.7566 - precision: 0.4056 - recall: 0.9891 - val_loss: 0.5561 - val_tp: 155.0000 - val_fp: 222.0000 - val_tn: 558.0000 - val_fn: 1.0000 - val_accuracy: 0.7618 - val_precision: 0.4111 - val_recall: 0.9936\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.5280 - tp: 4967.0000 - fp: 7403.0000 - tn: 17737.0000 - fn: 61.0000 - accuracy: 0.7526 - precision: 0.4015 - recall: 0.9879 - val_loss: 0.7183 - val_tp: 152.0000 - val_fp: 213.0000 - val_tn: 567.0000 - val_fn: 4.0000 - val_accuracy: 0.7682 - val_precision: 0.4164 - val_recall: 0.9744\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 400s 1s/step - loss: 0.5173 - tp: 4973.0000 - fp: 7454.0000 - tn: 17686.0000 - fn: 55.0000 - accuracy: 0.7511 - precision: 0.4002 - recall: 0.9891 - val_loss: 0.5781 - val_tp: 156.0000 - val_fp: 194.0000 - val_tn: 586.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7927 - val_precision: 0.4457 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 400s 1s/step - loss: 0.5166 - tp: 4955.0000 - fp: 6915.0000 - tn: 18225.0000 - fn: 73.0000 - accuracy: 0.7684 - precision: 0.4174 - recall: 0.9855 - val_loss: 0.5821 - val_tp: 151.0000 - val_fp: 188.0000 - val_tn: 592.0000 - val_fn: 5.0000 - val_accuracy: 0.7938 - val_precision: 0.4454 - val_recall: 0.9679\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 397s 1s/step - loss: 0.4964 - tp: 4951.0000 - fp: 6771.0000 - tn: 18369.0000 - fn: 77.0000 - accuracy: 0.7730 - precision: 0.4224 - recall: 0.9847 - val_loss: 0.6459 - val_tp: 145.0000 - val_fp: 198.0000 - val_tn: 582.0000 - val_fn: 11.0000 - val_accuracy: 0.7767 - val_precision: 0.4227 - val_recall: 0.9295\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.4909 - tp: 4964.0000 - fp: 6564.0000 - tn: 18576.0000 - fn: 64.0000 - accuracy: 0.7803 - precision: 0.4306 - recall: 0.9873 - val_loss: 0.6264 - val_tp: 151.0000 - val_fp: 168.0000 - val_tn: 612.0000 - val_fn: 5.0000 - val_accuracy: 0.8152 - val_precision: 0.4734 - val_recall: 0.9679\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.4755 - tp: 4966.0000 - fp: 6366.0000 - tn: 18774.0000 - fn: 62.0000 - accuracy: 0.7869 - precision: 0.4382 - recall: 0.9877 - val_loss: 0.5744 - val_tp: 153.0000 - val_fp: 212.0000 - val_tn: 568.0000 - val_fn: 3.0000 - val_accuracy: 0.7703 - val_precision: 0.4192 - val_recall: 0.9808\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.4754 - tp: 4968.0000 - fp: 6712.0000 - tn: 18428.0000 - fn: 60.0000 - accuracy: 0.7755 - precision: 0.4253 - recall: 0.9881 - val_loss: 0.5899 - val_tp: 155.0000 - val_fp: 212.0000 - val_tn: 568.0000 - val_fn: 1.0000 - val_accuracy: 0.7724 - val_precision: 0.4223 - val_recall: 0.9936\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 399s 1s/step - loss: 0.4601 - tp: 4971.0000 - fp: 6818.0000 - tn: 18322.0000 - fn: 57.0000 - accuracy: 0.7721 - precision: 0.4217 - recall: 0.9887 - val_loss: 0.5507 - val_tp: 154.0000 - val_fp: 196.0000 - val_tn: 584.0000 - val_fn: 2.0000 - val_accuracy: 0.7885 - val_precision: 0.4400 - val_recall: 0.9872\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 400s 1s/step - loss: 0.4689 - tp: 4973.0000 - fp: 6369.0000 - tn: 18771.0000 - fn: 55.0000 - accuracy: 0.7871 - precision: 0.4385 - recall: 0.9891 - val_loss: 0.6662 - val_tp: 153.0000 - val_fp: 198.0000 - val_tn: 582.0000 - val_fn: 3.0000 - val_accuracy: 0.7853 - val_precision: 0.4359 - val_recall: 0.9808\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 407s 1s/step - loss: 0.4541 - tp: 4963.0000 - fp: 6666.0000 - tn: 18474.0000 - fn: 65.0000 - accuracy: 0.7769 - precision: 0.4268 - recall: 0.9871 - val_loss: 0.7255 - val_tp: 154.0000 - val_fp: 196.0000 - val_tn: 584.0000 - val_fn: 2.0000 - val_accuracy: 0.7885 - val_precision: 0.4400 - val_recall: 0.9872\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 440s 1s/step - loss: 0.4592 - tp: 4966.0000 - fp: 6386.0000 - tn: 18754.0000 - fn: 62.0000 - accuracy: 0.7863 - precision: 0.4375 - recall: 0.9877 - val_loss: 0.6516 - val_tp: 149.0000 - val_fp: 187.0000 - val_tn: 593.0000 - val_fn: 7.0000 - val_accuracy: 0.7927 - val_precision: 0.4435 - val_recall: 0.9551\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 444s 1s/step - loss: 0.4424 - tp: 4981.0000 - fp: 6365.0000 - tn: 18775.0000 - fn: 47.0000 - accuracy: 0.7875 - precision: 0.4390 - recall: 0.9907 - val_loss: 0.6536 - val_tp: 152.0000 - val_fp: 192.0000 - val_tn: 588.0000 - val_fn: 4.0000 - val_accuracy: 0.7906 - val_precision: 0.4419 - val_recall: 0.9744\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "r = model5.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save('densenet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYUyZcMHr4cP"
   },
   "source": [
    "# EfficientB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "93EgJKLMr-ZZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQEu0VICsEOX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      " 24182784/258076736 [=>............................] - ETA: 4:00"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB7(include_top=False, weights='imagenet', pooling='max', input_shape=(224,224,3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXAG4PbJ20Cv"
   },
   "outputs": [],
   "source": [
    "x=Flatten()(base_model.output)\n",
    "prediction=Dense(6,activation='softmax')(x)\n",
    "model6=Model(inputs=base_model.input,outputs=prediction)\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUM4PwXXsIly"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model6.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY_Y7VtKsOFM"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "r = model6.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save('efficientB7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MPokbS3sQj5"
   },
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ax7NdPhsVho"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uC9i2bRLsXiO"
   },
   "outputs": [],
   "source": [
    "Image_size=[224,224]\n",
    "vgg=VGG19(input_shape=Image_size+[3],weights='imagenet',include_top=False)\n",
    "vgg.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbU0NPXrsZwe"
   },
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fF3upltnsbq0"
   },
   "outputs": [],
   "source": [
    "x=Flatten()(vgg.output)\n",
    "prediction=Dense(6,activation='sigmoid')(x)\n",
    "model7=Model(inputs=vgg.input,outputs=prediction)\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRIhAlfeseDi"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model7.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x49zgi-Csh5G"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "r = model7.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.save('vgg19.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9TIUIEaswx4"
   },
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZWz2M9ww2B2"
   },
   "outputs": [],
   "source": [
    "# Common lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, AveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HxrOANkw6Hb"
   },
   "outputs": [],
   "source": [
    "# When export model, these preprocessing layers will be saved along with the rest of model\n",
    "resize_and_rescale = Sequential([\n",
    "    Resizing(227, 227),\n",
    "    Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjaYldccsv3Y"
   },
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "create_dir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNKkA3Gkw-2l"
   },
   "outputs": [],
   "source": [
    "lamb = 0.9\n",
    "\n",
    "model = Sequential([\n",
    "    # Preprocessing layer\n",
    "    resize_and_rescale,\n",
    "    \n",
    "    InputLayer((227, 227, 3)),\n",
    "    \n",
    "    # 1st layer\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu', kernel_regularizer=l2(lamb), name='conv1'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 2nd layer\n",
    "    Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv2'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 3rd layer\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv3'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 4th layer\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv4'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 5th layer\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv5'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Flatten\n",
    "    Flatten(),\n",
    "    \n",
    "    # 6th layer\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # 7th layer\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # 8th layer (output)\n",
    "    Dense(units=6, activation='softmax')\n",
    "], name='AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atvypRMAxE6b"
   },
   "outputs": [],
   "source": [
    "#Create folder contains model's files\n",
    "model_dir = 'models/alexnet'\n",
    "model_file = 'best_alexnet.hdf5'\n",
    "create_dir(model_dir)\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(model_dir, model_file),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=30,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), \n",
    "                              patience=7, min_delta=1e-3, verbose=1, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RONSDb1xLw8"
   },
   "outputs": [],
   "source": [
    "# Initialize TensorBoard\n",
    "log_dir = 'models/alexnet/logs' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-GqohbbxToG"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model8.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWCvoQ8hxUgK"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "r = model8.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save('alexNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78DmGYBRxjBP"
   },
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iap6qRO1xp72"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_06wmblLx0WB"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((150,150,3))\n",
    "base_model=tf.keras.applications.xception.Xception(include_top=False, weights=\"imagenet\",input_shape=(150,150,3), pooling='avg') \n",
    "x=base_model(inputs)\n",
    "output=layers.Dense(6, activation='softmax')(x)\n",
    "model9=tf.keras.models.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3s_A6ppxqo5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uddogtgexmje"
   },
   "outputs": [],
   "source": [
    "# telling the model what cost and optimization method to use\n",
    "model9.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQClID4cxr4W"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "r = model9.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.save('xception.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cb5dac6523e42f8bae47b9eaac74eab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16043d2971f344b39766ecc27575da64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29d3b3d6d5fc4b93b6e31a45736cd84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cb5dac6523e42f8bae47b9eaac74eab",
      "placeholder": "​",
      "style": "IPY_MODEL_9ff3b18963a744c49bfd00c34a530e75",
      "value": "100%"
     }
    },
    "3ddd31cab75e4b17b221f04588a00073": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48a09c594ebd4d4c92ef6f672f7227cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "655508317753458885ab82ae2c11dec6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29d3b3d6d5fc4b93b6e31a45736cd84c",
       "IPY_MODEL_cf73cb04b1074ea894478a8442f3f5af",
       "IPY_MODEL_f832831728454694a02da9b7b512a8bd"
      ],
      "layout": "IPY_MODEL_48a09c594ebd4d4c92ef6f672f7227cf"
     }
    },
    "9ff3b18963a744c49bfd00c34a530e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2c1d1a7888b41f9a421202d5c1fe769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf73cb04b1074ea894478a8442f3f5af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed2d1476f86e49bb8a4621432c50d035",
      "max": 52147035,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2c1d1a7888b41f9a421202d5c1fe769",
      "value": 52147035
     }
    },
    "ed2d1476f86e49bb8a4621432c50d035": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f832831728454694a02da9b7b512a8bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16043d2971f344b39766ecc27575da64",
      "placeholder": "​",
      "style": "IPY_MODEL_3ddd31cab75e4b17b221f04588a00073",
      "value": " 49.7M/49.7M [00:03&lt;00:00, 14.5MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
